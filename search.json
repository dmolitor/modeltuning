[{"path":"https://www.dmolitor.com/modelselection/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 modelselection authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://www.dmolitor.com/modelselection/articles/scaling-with-aws.html","id":"requisite-packages","dir":"Articles","previous_headings":"","what":"Requisite Packages","title":"Scaling with AWS","text":"","code":"library(e1071) library(future) library(modeltuning) # devtools::install_github(\"dmolitor/modeltuning\") library(parallelly) library(paws) library(rsample) library(yardstick)"},{"path":[]},{"path":"https://www.dmolitor.com/modelselection/articles/scaling-with-aws.html","id":"data-prep","dir":"Articles","previous_headings":"Data and Model Prep","what":"Data Prep","title":"Scaling with AWS","text":"’ll training classification model iris data-set predict whether flower’s species virginica . First, let’s generate bunch synthetic data observations adding random noise original iris features combining one big dataframe.","code":"iris_new <- do.call(   what = rbind,   args = replicate(n = 10, iris, simplify = FALSE) ) |>   transform(     Sepal.Length = jitter(Sepal.Length, 0.1),     Sepal.Width = jitter(Sepal.Width, 0.1),     Petal.Length = jitter(Petal.Length, 0.1),     Petal.Width = jitter(Petal.Width, 0.1),     Species = factor(Species == \"virginica\")   )  # Shuffle the data-set iris_new <- iris_new[sample(1:nrow(iris_new), nrow(iris_new)), ]  # Quick overview of the dataset summary(iris_new[, 1:4]) #   Sepal.Length    Sepal.Width     Petal.Length     Petal.Width      #  Min.   :4.299   Min.   :1.999   Min.   :0.9986   Min.   :0.09801   #  1st Qu.:5.101   1st Qu.:2.799   1st Qu.:1.5984   1st Qu.:0.29972   #  Median :5.799   Median :3.001   Median :4.3499   Median :1.30126   #  Mean   :5.843   Mean   :3.057   Mean   :3.7580   Mean   :1.19938   #  3rd Qu.:6.400   3rd Qu.:3.302   3rd Qu.:5.1002   3rd Qu.:1.80059   #  Max.   :7.901   Max.   :4.401   Max.   :6.9020   Max.   :2.50193"},{"path":"https://www.dmolitor.com/modelselection/articles/scaling-with-aws.html","id":"grid-search-specification","dir":"Articles","previous_headings":"Data and Model Prep","what":"Grid Search Specification","title":"Scaling with AWS","text":"Now ’ve got data prepped, let’s specify predictive modeling approach. analysis ’m going train Support Vector classifier using e1071 package, ’m going use Grid Search combination 5-fold Cross-Validation find optimal values cost kernel hyper-parameters. Now ’ve specified Grid Search schema let’s check hyper-parameter grid see many models ’re going estimate.","code":"# Create a splitter function that will return CV folds splitter_fn <- function(data) lapply(vfold_cv(data, v = 5)$splits, \\(y) y$in_id)  iris_grid <- GridSearchCV$new(   learner = svm,   tune_params = list(     cost = c(0.01, 0.1, 0.5, 1, 3, 6),     kernel = c(\"polynomial\", \"radial\", \"sigmoid\")   ),   learner_args = list(     scale = TRUE,     type = \"C-classification\",     probability = TRUE   ),   splitter = splitter_fn,   scorer = list(     accuracy = accuracy_vec,     f_measure = f_meas_vec,     auc = roc_auc_vec   ),   prediction_args = list(     accuracy = NULL,     f_measure = NULL,     auc = list(probability = TRUE)   ),   convert_predictions = list(     accuracy = NULL,     f_measure = NULL,     auc = function(.x) attr(.x, \"probabilities\")[, \"FALSE\"]   ),   optimize_score = \"max\" ) cat(\"We will estimate\", nrow(iris_grid$tune_params), \"SVM models\\n\") # We will estimate 18 SVM models"},{"path":"https://www.dmolitor.com/modelselection/articles/scaling-with-aws.html","id":"launch-aws-resources","dir":"Articles","previous_headings":"","what":"Launch AWS Resources","title":"Scaling with AWS","text":"speed estimation models, let’s create remote cluster 6 worker nodes estimate models parallel.","code":""},{"path":"https://www.dmolitor.com/modelselection/articles/scaling-with-aws.html","id":"launch-ec2-instances","dir":"Articles","previous_headings":"Launch AWS Resources","what":"Launch EC2 Instances","title":"Scaling with AWS","text":"First, launch 6 instances using custom AMI contains R bunch essential R packages. AMI available community AMI definitely good AMIs comprehensive set R packages corresponding tools installed. Note: parameters need specify launching EC2 instances may vary greatly depending account’s security configurations. Now ’ve launched instances need wait respond \"running\" try anything (also need wait ~ 1 minute instances initialize ’ll reject SSH login attempts).","code":"ec2_client <- ec2()  # Request Instances instance_req <- ec2_client$run_instances(   ImageId = \"ami-06dd49fc9e3a5acee\",   InstanceType = \"t2.large\",   KeyName = key_name,   MaxCount = 6,   MinCount = 6,   InstanceInitiatedShutdownBehavior = \"terminate\",   SecurityGroupIds = security_group,   # This names the instances   TagSpecifications = list(     list(       ResourceType = \"instance\",       Tags = list(         list(           Key = \"Name\",           Value = \"Worker Node\"         )       )     )   ) ) # Chalk up a quick function to return instance IDs from our request instance_ids <- function(response) {   vapply(response$Instances, function(i) i$InstanceId, character(1)) }  # Wait for instances to all respond as 'running' while(   !all(     vapply(       ec2_client$       describe_instances(InstanceIds = instance_ids(instance_req))$       Reservations[[1]]$       Instances,       function(i) i$State$Name,       character(1)     ) == \"running\"   ) ) {   Sys.sleep(5) }  # Rough heuristic -- give additional 45 seconds for instances to initialize Sys.sleep(45)"},{"path":"https://www.dmolitor.com/modelselection/articles/scaling-with-aws.html","id":"create-cluster","dir":"Articles","previous_headings":"Launch AWS Resources","what":"Create Cluster","title":"Scaling with AWS","text":"Now, order set compute cluster need get IP addresses instances. Finally, can create compute cluster worker nodes via SSH.","code":"# Get public IPs inst_public_ips <- vapply(   ec2_client$     describe_instances(InstanceIds = instance_ids(instance_req))$     Reservations[[1]]$     Instances,   function(i) i$PublicIpAddress,   character(1) ) cl <- makeClusterPSOCK(   worker = inst_public_ips,   user = \"ubuntu\",   rshopts = c(\"-o\", \"StrictHostKeyChecking=no\",               \"-o\", \"IdentitiesOnly=yes\",               \"-i\", pem_fp), # Local filepath to private SSH key-pair   connectTimeout = 25,   tries = 3 )"},{"path":"https://www.dmolitor.com/modelselection/articles/scaling-with-aws.html","id":"estimate-models","dir":"Articles","previous_headings":"","what":"Estimate Models","title":"Scaling with AWS","text":"Now ’ve created compute cluster, can use future package specify parallelization plan. Since modeltuning built top future framework, automatically parallelize model estimation across 6-worker cluster. following parallelization topology basically telling future parallelize grid-search models across compute cluster, parallelize model’s cross-validation across cores instance evaluated . Finally, let’s estimate Grid Search models parallel!","code":"plan(   list(     tweak(cluster, workers = cl),     multisession   ) ) iris_grid_fitted <- iris_grid$fit(   formula = Species ~ .,   data = iris_new,   progress = TRUE )"},{"path":"https://www.dmolitor.com/modelselection/articles/scaling-with-aws.html","id":"best-modelparameters","dir":"Articles","previous_headings":"","what":"Best Model/Parameters","title":"Scaling with AWS","text":"Let’s check info best model.","code":"best_idx <- iris_grid_fitted$best_idx metrics <- iris_grid_fitted$metrics  # Print model metrics of best model cat(   \" Accuracy:\", round(100 * metrics$accuracy[[best_idx]], 2),   \"%\\nF-Measure:\", round(100 * metrics$f_measure[[best_idx]], 2),   \"%\\n      AUC:\", round(metrics$auc[[best_idx]], 4), \"\\n\" ) #  Accuracy: 98.4 % # F-Measure: 98.81 % #       AUC: 0.9993  params <- iris_grid_fitted$best_params  # Print the best hyper-parameters cat(   \"  Optimal Cost:\", params[[\"cost\"]],   \"\\nOptimal Kernel:\", params[[\"kernel\"]], \"\\n\" ) #   Optimal Cost: 6  # Optimal Kernel: polynomial"},{"path":"https://www.dmolitor.com/modelselection/articles/scaling-with-aws.html","id":"kill-aws-resources","dir":"Articles","previous_headings":"","what":"Kill AWS Resources","title":"Scaling with AWS","text":"Now ’ve completed mini-analysis let’s make sure kill AWS resources. Since ’ve done launch EC2 instances, consists making sure instances shut .","code":"ec2_client$stop_instances(   InstanceIds = instance_ids(instance_req) )"},{"path":"https://www.dmolitor.com/modelselection/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel Molitor. Author, maintainer.","code":""},{"path":"https://www.dmolitor.com/modelselection/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Molitor D (2025). modeltuning: Model Selection Tuning Utilities. R package version 0.1.0, https://www.dmolitor.com/modeltuning/.","code":"@Manual{,   title = {modeltuning: Model Selection and Tuning Utilities},   author = {Daniel Molitor},   year = {2025},   note = {R package version 0.1.0},   url = {https://www.dmolitor.com/modeltuning/}, }"},{"path":"https://www.dmolitor.com/modelselection/index.html","id":"modeltuning-","dir":"","previous_headings":"","what":"Model Selection and Tuning Utilities","title":"Model Selection and Tuning Utilities","text":"goal modeltuning provide common model selection tuning utilities intuitive manner. Additionally, modeltuning aims : Fairly lightweight force learn entirely new modeling paradigm Model/type agnostic work easily R modeling packages various data types including data frames, standard dense matrices, Matrix sparse matrices Easily parallelizable; modeltuning built top future package compatible (many!) available parallelization backends.","code":""},{"path":"https://www.dmolitor.com/modelselection/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Model Selection and Tuning Utilities","text":"can install development version modeltuning :","code":"# install.packages(\"pak\") pak::pkg_install(\"dmolitor/modeltuning\")"},{"path":"https://www.dmolitor.com/modelselection/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Model Selection and Tuning Utilities","text":"simple examples use built-iris data-set illustrate basic functionality modeltuning.","code":""},{"path":"https://www.dmolitor.com/modelselection/index.html","id":"cross-validation","dir":"","previous_headings":"Usage","what":"Cross Validation","title":"Model Selection and Tuning Utilities","text":"First ’ll train binary classification Decision Tree model predict whether flowers iris Species virginica ’ll specify 3-fold cross validation scheme stratification Species estimate model’s true error rate. First, let’s split data train test set. Now, let’s specify fit 3-fold cross validation scheme calculate F Measure, Accuracy, ROC AUC hold-set evaluation metrics. Now, let’s check evaluation metrics averaged across folds.","code":"library(future) library(modeltuning) library(rpart) library(rsample) library(yardstick)  iris_new <- iris[sample(1:nrow(iris), nrow(iris)), ] iris_new$Species <- factor(iris_new$Species == \"virginica\") iris_train <- iris_new[1:100, ] iris_test <- iris_new[101:150, ] # Specify cross validation schema iris_cv <- CV$new(   learner = rpart,   learner_args = list(method = \"class\"),   splitter = cv_split,   splitter_args = list(v = 3),   scorer = list(     \"f_meas\" = f_meas_vec,     \"accuracy\" = accuracy_vec,     \"auc\" = roc_auc_vec   ),    prediction_args = list(     \"f_meas\" = list(type = \"class\"),     \"accuracy\" = list(type = \"class\"),      \"auc\" = list(type = \"prob\")   ),   convert_predictions = list(     NULL,     NULL,     function(.x) .x[, \"FALSE\"]   ) )  # Fit cross validated model iris_cv_fitted <- iris_cv$fit(formula = Species ~ ., data = iris_new) cat(   \"F-Measure:\", paste0(round(100 * iris_cv_fitted$mean_metrics$f_meas, 2), \"%\"),   \"\\n Accuracy:\", paste0(round(100 * iris_cv_fitted$mean_metrics$accuracy, 2), \"%\"),   \"\\n      AUC:\", paste0(round(iris_cv_fitted$mean_metrics$auc, 4)) ) #> F-Measure: 95.97%  #>  Accuracy: 94.67%  #>       AUC: 0.9435"},{"path":"https://www.dmolitor.com/modelselection/index.html","id":"grid-search","dir":"","previous_headings":"Usage","what":"Grid Search","title":"Model Selection and Tuning Utilities","text":"Another common model-tuning method grid search. ’ll use tune minsplit maxdepth parameters decision tree. choose optimal hyper-parameters maximize ROC AUC validation set. Let’s check details optimal decision tree model.","code":"# Specify Grid Search schema iris_grid <- GridSearch$new(   learner = rpart,   learner_args = list(method = \"class\"),   tune_params = list(     minsplit = seq(10, 30, by = 5),     maxdepth = seq(20, 30, by = 2)   ),   evaluation_data = list(x = iris_test, y = iris_test$Species),   scorer = list(     accuracy = accuracy_vec,     auc = roc_auc_vec   ),   optimize_score = \"max\",   prediction_args = list(     accuracy = list(type = \"class\"),     auc = list(type = \"prob\")   ),   convert_predictions = list(     accuracy = NULL,     auc = function(i) i[, \"FALSE\"]   ) )  # Fit models across grid iris_grid_fitted <- iris_grid$fit(   formula = Species ~ .,   data = iris_train ) cat(   \"Optimal Hyper-parameters:\\n  -\",   paste0(     paste0(names(iris_grid_fitted$best_params), \": \", iris_grid_fitted$best_params),     collapse = \"\\n  - \"   ),   \"\\nOptimal ROC AUC:\",    round(iris_grid_fitted$best_metric, 4) ) #> Optimal Hyper-parameters: #>   - minsplit: 10 #>   - maxdepth: 20  #> Optimal ROC AUC: 0.9545"},{"path":"https://www.dmolitor.com/modelselection/index.html","id":"grid-search-with-cross-validation","dir":"","previous_headings":"Usage","what":"Grid Search with cross validation","title":"Model Selection and Tuning Utilities","text":"Finally, modeltuning supports model-tuning Grid Search using cross validation estimate model’s true error rate instead hold-validation set. ’ll use cross validation tune parameters . Let’s check details optimal decision tree model.","code":"# Specify Grid Search schema with cross validation iris_grid_cv <- GridSearchCV$new(   learner = rpart,   learner_args = list(method = \"class\"),   tune_params = list(     minsplit = seq(10, 30, by = 5),     maxdepth = seq(20, 30, by = 2)   ),   splitter = cv_split,   splitter_args = list(v = 3),   scorer = list(     accuracy = accuracy_vec,     auc = roc_auc_vec   ),   optimize_score = \"max\",   prediction_args = list(     accuracy = list(type = \"class\"),     auc = list(type = \"prob\")   ),   convert_predictions = list(     accuracy = NULL,     auc = function(i) i[, \"FALSE\"]   ) )  # Fit models across grid iris_grid_cv_fitted <- iris_grid_cv$fit(   formula = Species ~ .,   data = iris_train ) cat(   \"Optimal Hyper-parameters:\\n  -\",   paste0(     paste0(       names(iris_grid_cv_fitted$best_params),        \": \",        iris_grid_cv_fitted$best_params     ),     collapse = \"\\n  - \"   ),   \"\\nOptimal ROC AUC:\",    round(iris_grid_cv_fitted$best_metric, 4) ) #> Optimal Hyper-parameters: #>   - minsplit: 15 #>   - maxdepth: 28  #> Optimal ROC AUC: 0.9494"},{"path":"https://www.dmolitor.com/modelselection/index.html","id":"parallelization","dir":"","previous_headings":"Usage","what":"Parallelization","title":"Model Selection and Tuning Utilities","text":"noted , modeltuning built top future package can utilize parallelization method supported future package fitting cross-validated models tuning models grid search. code evaluates cross-validated binary classification model using local parallelization. voila!","code":"plan(multisession, workers = 5)  # Fit Cross Validated model iris_cv_fitted <- iris_cv$fit(formula = Species ~ ., data = iris_train)  # Model performance metrics iris_cv_fitted$mean_metrics #> $f_meas #> [1] 0.9632626 #>  #> $accuracy #> [1] 0.9499472 #>  #> $auc #> [1] 0.9388356"},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictive Models with Cross Validation — CV","title":"Predictive Models with Cross Validation — CV","text":"CV allows user specify cross validation scheme complete flexibility model, data splitting function, performance metrics, among essential parameters.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Predictive Models with Cross Validation — CV","text":"learner Predictive modeling function. scorer List performance metric functions. splitter Function splits data cross validation folds.","code":""},{"path":[]},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Predictive Models with Cross Validation — CV","text":"CV$fit() CV$new() CV$clone()","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"method-fit-","dir":"Reference","previous_headings":"","what":"Method fit()","title":"Predictive Models with Cross Validation — CV","text":"fit performs cross validation user-specified parameters.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictive Models with Cross Validation — CV","text":"","code":"CV$fit(formula = NULL, data = NULL, x = NULL, y = NULL, progress = FALSE)"},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictive Models with Cross Validation — CV","text":"formula object class formula: symbolic description model fitted. data optional data frame, object containing variables model. data provided, formula handled depends $learner. x Predictor data (independent variables), alternative interface data formula. y Response vector (dependent variable), alternative interface data formula. progress Logical; indicating whether print progress across cross validation folds.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predictive Models with Cross Validation — CV","text":"fit follows standard R modeling convention surfacing formula modeling interface well alternate matrix option. user use whichever interface supported specified $learner function.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Predictive Models with Cross Validation — CV","text":"object class FittedCV.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictive Models with Cross Validation — CV","text":"","code":"if (require(e1071) && require(rpart) && require(rsample) && require(yardstick)) {   iris_new <- iris[sample(1:nrow(iris), nrow(iris)), ]   iris_new$Species <- factor(iris_new$Species == \"virginica\")    # Create a sampling function that returns CV folds   sampling_fn <- function(data) lapply(rsample::vfold_cv(data, v = 3)$splits, \\(y) y$in_id)    ### Decision Tree Example    iris_cv <- CV$new(     learner = rpart::rpart,     learner_args = list(method = \"class\"),     splitter = sampling_fn,     scorer = list(\"accuracy\" = yardstick::accuracy_vec),     prediction_args = list(type = \"class\")   )   iris_cv_fitted <- iris_cv$fit(formula = Species ~ ., data = iris_new)    ### Example with multiple metric functions    iris_cv <- CV$new(     learner = rpart::rpart,     learner_args = list(method = \"class\"),     splitter = sampling_fn,     scorer = list(       \"f_meas\" = yardstick::f_meas_vec,       \"accuracy\" = yardstick::accuracy_vec,       \"roc_auc\" = yardstick::roc_auc_vec,       \"pr_auc\" = yardstick::pr_auc_vec     ),     prediction_args = list(       \"f_meas\" = list(type = \"class\"),       \"accuracy\" = list(type = \"class\"),       \"roc_auc\" = list(type = \"prob\"),       \"pr_auc\" = list(type = \"prob\")     ),     convert_predictions = list(       NULL,       NULL,       function(i) i[, \"FALSE\"],       function(i) i[, \"FALSE\"]     )   )   iris_cv_fitted <- iris_cv$fit(formula = Species ~ ., data = iris_new)    # Print the mean performance metrics across CV folds   iris_cv_fitted$mean_metrics    # Grab the final model fitted on the full dataset   iris_cv_fitted$model    ### OLS Example    mtcars_cv <- CV$new(     learner = lm,     splitter = sampling_fn,     scorer = list(\"rmse\" = yardstick::rmse_vec, \"mae\" = yardstick::mae_vec)   )    mtcars_cv_fitted <- mtcars_cv$fit(     formula = mpg ~ .,     data = mtcars   )    ### Matrix interface example - SVM    mtcars_x <- model.matrix(mpg ~ . - 1, mtcars)   mtcars_y <- mtcars$mpg    mtcars_cv <- CV$new(     learner = e1071::svm,     learner_args = list(scale = TRUE, kernel = \"polynomial\", cross = 0),     splitter = sampling_fn,     scorer = list(\"rmse\" = yardstick::rmse_vec, \"mae\" = yardstick::mae_vec)   )   mtcars_cv_fitted <- mtcars_cv$fit(     x = mtcars_x,     y = mtcars_y   ) }"},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Predictive Models with Cross Validation — CV","text":"Create new CV object.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictive Models with Cross Validation — CV","text":"","code":"CV$new(   learner = NULL,   splitter = NULL,   scorer = NULL,   learner_args = NULL,   splitter_args = NULL,   scorer_args = NULL,   prediction_args = NULL,   convert_predictions = NULL )"},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictive Models with Cross Validation — CV","text":"learner Function estimates predictive model. essential function support either formula interface formula data arguments, alternate matrix interface x y arguments. splitter function computes cross validation folds input data set pre-computed list cross validation fold indices. splitter function, must data argument input data, must return list cross validation fold indices. splitter list integers, number cross validation folds length(splitter) element contains indices data observations included fold. scorer named list metric functions evaluate model performance cross validation fold. provided metric function must truth estimate arguments true outcome values predicted outcome values respectively, must return single numeric metric value. learner_args named list additional arguments pass learner. splitter_args named list additional arguments pass splitter. scorer_args named list additional arguments pass scorer. scorer_args must either length 1 length(scorer) case different arguments passed scoring function. prediction_args named list additional arguments pass predict. prediction_args must either length 1 length(scorer) case different arguments passed scoring function. convert_predictions list functions convert predicted values prior evaluated metric functions supplied scorer. list either length 1, case function applied predicted values, length(scorer) case function convert_predictions correspond function scorer.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"Predictive Models with Cross Validation — CV","text":"object class CV.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Predictive Models with Cross Validation — CV","text":"objects class cloneable method.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictive Models with Cross Validation — CV","text":"","code":"CV$clone(deep = FALSE)"},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictive Models with Cross Validation — CV","text":"deep Whether make deep clone.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/CV.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictive Models with Cross Validation — CV","text":"","code":"## ------------------------------------------------ ## Method `CV$fit` ## ------------------------------------------------  if (require(e1071) && require(rpart) && require(rsample) && require(yardstick)) {   iris_new <- iris[sample(1:nrow(iris), nrow(iris)), ]   iris_new$Species <- factor(iris_new$Species == \"virginica\")    # Create a sampling function that returns CV folds   sampling_fn <- function(data) lapply(rsample::vfold_cv(data, v = 3)$splits, \\(y) y$in_id)    ### Decision Tree Example    iris_cv <- CV$new(     learner = rpart::rpart,     learner_args = list(method = \"class\"),     splitter = sampling_fn,     scorer = list(\"accuracy\" = yardstick::accuracy_vec),     prediction_args = list(type = \"class\")   )   iris_cv_fitted <- iris_cv$fit(formula = Species ~ ., data = iris_new)    ### Example with multiple metric functions    iris_cv <- CV$new(     learner = rpart::rpart,     learner_args = list(method = \"class\"),     splitter = sampling_fn,     scorer = list(       \"f_meas\" = yardstick::f_meas_vec,       \"accuracy\" = yardstick::accuracy_vec,       \"roc_auc\" = yardstick::roc_auc_vec,       \"pr_auc\" = yardstick::pr_auc_vec     ),     prediction_args = list(       \"f_meas\" = list(type = \"class\"),       \"accuracy\" = list(type = \"class\"),       \"roc_auc\" = list(type = \"prob\"),       \"pr_auc\" = list(type = \"prob\")     ),     convert_predictions = list(       NULL,       NULL,       function(i) i[, \"FALSE\"],       function(i) i[, \"FALSE\"]     )   )   iris_cv_fitted <- iris_cv$fit(formula = Species ~ ., data = iris_new)    # Print the mean performance metrics across CV folds   iris_cv_fitted$mean_metrics    # Grab the final model fitted on the full dataset   iris_cv_fitted$model    ### OLS Example    mtcars_cv <- CV$new(     learner = lm,     splitter = sampling_fn,     scorer = list(\"rmse\" = yardstick::rmse_vec, \"mae\" = yardstick::mae_vec)   )    mtcars_cv_fitted <- mtcars_cv$fit(     formula = mpg ~ .,     data = mtcars   )    ### Matrix interface example - SVM    mtcars_x <- model.matrix(mpg ~ . - 1, mtcars)   mtcars_y <- mtcars$mpg    mtcars_cv <- CV$new(     learner = e1071::svm,     learner_args = list(scale = TRUE, kernel = \"polynomial\", cross = 0),     splitter = sampling_fn,     scorer = list(\"rmse\" = yardstick::rmse_vec, \"mae\" = yardstick::mae_vec)   )   mtcars_cv_fitted <- mtcars_cv$fit(     x = mtcars_x,     y = mtcars_y   ) } #> Loading required package: e1071 #> Loading required package: rpart #> Loading required package: rsample #>  #> Attaching package: ‘rsample’ #> The following object is masked from ‘package:e1071’: #>  #>     permutations #> Loading required package: yardstick"},{"path":"https://www.dmolitor.com/modelselection/reference/FittedCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitted, Cross-Validated Predictive Models — FittedCV","title":"Fitted, Cross-Validated Predictive Models — FittedCV","text":"FittedCV fitted, cross-validated predictive model object returned CV$fit() contains relevant model components, cross-validation metrics, validation set predicted values, etc.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedCV.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Fitted, Cross-Validated Predictive Models — FittedCV","text":"folds list length $nfolds element contains indices observations contained fold. model Predictive model fitted full data set. mean_metrics Numeric list; Cross-validation performance metrics averaged across folds. metrics Numeric list; Cross-validation performance metrics fold. nfolds integer specifying number cross-validation folds. predictions list containing predicted hold-values every fold.","code":""},{"path":[]},{"path":"https://www.dmolitor.com/modelselection/reference/FittedCV.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Fitted, Cross-Validated Predictive Models — FittedCV","text":"FittedCV$new() FittedCV$clone()","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedCV.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Fitted, Cross-Validated Predictive Models — FittedCV","text":"Create new FittedCV object.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedCV.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitted, Cross-Validated Predictive Models — FittedCV","text":"","code":"FittedCV$new(folds, model, metrics, nfolds, predictions)"},{"path":"https://www.dmolitor.com/modelselection/reference/FittedCV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitted, Cross-Validated Predictive Models — FittedCV","text":"folds list length $nfolds element contains indices observations contained fold. model Predictive model fitted full data set. metrics Numeric list; Cross-validation performance metrics fold. nfolds integer specifying number cross-validation folds. predictions list containing predicted hold-values every fold.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedCV.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Fitted, Cross-Validated Predictive Models — FittedCV","text":"object class FittedCV.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedCV.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Fitted, Cross-Validated Predictive Models — FittedCV","text":"objects class cloneable method.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedCV.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitted, Cross-Validated Predictive Models — FittedCV","text":"","code":"FittedCV$clone(deep = FALSE)"},{"path":"https://www.dmolitor.com/modelselection/reference/FittedCV.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitted, Cross-Validated Predictive Models — FittedCV","text":"deep Whether make deep clone.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearch.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitted Models across a Tuning Grid of Hyper-parameters — FittedGridSearch","title":"Fitted Models across a Tuning Grid of Hyper-parameters — FittedGridSearch","text":"FittedGridSearch object containing fitted predictive models across tuning grid hyper-parameters returned GridSearch$fit() well relevant model information best performing model, best hyper-parameters, etc.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearch.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Fitted Models across a Tuning Grid of Hyper-parameters — FittedGridSearch","text":"best_idx integer specifying index $models contains best-performing model. best_metric performance metric best model validation data. best_model best performing predictive model. best_params named list hyper-parameters result optimal predictive model. tune_params Data.frame full hyper-parameter grid. models List predictive models every value $tune_params. metrics Numeric list; Cross-validation performance metrics fold. predictions list containing predicted hold-values every fold.","code":""},{"path":[]},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearch.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Fitted Models across a Tuning Grid of Hyper-parameters — FittedGridSearch","text":"FittedGridSearch$new() FittedGridSearch$clone()","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearch.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Fitted Models across a Tuning Grid of Hyper-parameters — FittedGridSearch","text":"Create new FittedGridSearch object.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearch.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitted Models across a Tuning Grid of Hyper-parameters — FittedGridSearch","text":"","code":"FittedGridSearch$new(tune_params, models, metrics, predictions, optimize_score)"},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitted Models across a Tuning Grid of Hyper-parameters — FittedGridSearch","text":"tune_params Data.frame full hyper-parameter grid. models List predictive models every value $tune_params. metrics List performance metrics validation data every model $models. predictions list containing predicted values validation data every model $models. optimize_score Either \"max\" \"min\" indicating whether specified performance metric maximized minimized find optimal predictive model.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearch.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Fitted Models across a Tuning Grid of Hyper-parameters — FittedGridSearch","text":"object class FittedGridSearch.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearch.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Fitted Models across a Tuning Grid of Hyper-parameters — FittedGridSearch","text":"objects class cloneable method.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearch.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitted Models across a Tuning Grid of Hyper-parameters — FittedGridSearch","text":"","code":"FittedGridSearch$clone(deep = FALSE)"},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearch.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitted Models across a Tuning Grid of Hyper-parameters — FittedGridSearch","text":"deep Whether make deep clone.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearchCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitted Models with Cross Validation across a Tuning Grid of Hyper-parameters — FittedGridSearchCV","title":"Fitted Models with Cross Validation across a Tuning Grid of Hyper-parameters — FittedGridSearchCV","text":"FittedGridSearchCV object containing fitted predictive models across tuning grid hyper-parameters returned GridSearchCV$fit() well relevant model information best performing model, best hyper-parameters, etc.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearchCV.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Fitted Models with Cross Validation across a Tuning Grid of Hyper-parameters — FittedGridSearchCV","text":"best_idx integer specifying index $models contains best-performing model. best_metric average performance metric best model across cross-validation folds. best_model best performing predictive model. best_params named list hyper-parameters result optimal predictive model. folds list length $models element contains list cross-validation indices fold. tune_params data.frame full hyper-parameter grid. models List predictive models every value $tune_params. metrics Numeric list; Cross-validation performance metrics every model $models. predictions list containing cross-validation fold predictions model $models.","code":""},{"path":[]},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearchCV.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Fitted Models with Cross Validation across a Tuning Grid of Hyper-parameters — FittedGridSearchCV","text":"FittedGridSearchCV$new() FittedGridSearchCV$clone()","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearchCV.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Fitted Models with Cross Validation across a Tuning Grid of Hyper-parameters — FittedGridSearchCV","text":"Create new FittedGridSearchCV object.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearchCV.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitted Models with Cross Validation across a Tuning Grid of Hyper-parameters — FittedGridSearchCV","text":"","code":"FittedGridSearchCV$new(   tune_params,   models,   folds,   metrics,   predictions,   optimize_score )"},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearchCV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitted Models with Cross Validation across a Tuning Grid of Hyper-parameters — FittedGridSearchCV","text":"tune_params Data.frame full hyper-parameter grid. models List predictive models every value $tune_params. folds List cross-validation indices every value $tune_params. metrics List cross-validation performance metrics every model $models. predictions list containing predicted values cross-validation folds every model $models. optimize_score Either \"max\" \"min\" indicating whether specified performance metric maximized minimized find optimal predictive model.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearchCV.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Fitted Models with Cross Validation across a Tuning Grid of Hyper-parameters — FittedGridSearchCV","text":"object class FittedGridSearchCV.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearchCV.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Fitted Models with Cross Validation across a Tuning Grid of Hyper-parameters — FittedGridSearchCV","text":"objects class cloneable method.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearchCV.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitted Models with Cross Validation across a Tuning Grid of Hyper-parameters — FittedGridSearchCV","text":"","code":"FittedGridSearchCV$clone(deep = FALSE)"},{"path":"https://www.dmolitor.com/modelselection/reference/FittedGridSearchCV.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitted Models with Cross Validation across a Tuning Grid of Hyper-parameters — FittedGridSearchCV","text":"deep Whether make deep clone.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":null,"dir":"Reference","previous_headings":"","what":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"GridSearch allows user specify Grid Search schema tuning predictive model hyper-parameters complete flexibility predictive model performance metrics.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"learner Predictive modeling function. scorer List performance metric functions. tune_params Data.frame full hyper-parameter grid created $tune_params","code":""},{"path":[]},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"GridSearch$fit() GridSearch$new() GridSearch$clone()","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"method-fit-","dir":"Reference","previous_headings":"","what":"Method fit()","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"fit tunes user-specified model hyper-parameters via Grid Search.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"","code":"GridSearch$fit(   formula = NULL,   data = NULL,   x = NULL,   y = NULL,   progress = FALSE )"},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"formula object class formula: symbolic description model fitted. data optional data frame, object containing variables model. data provided, formula handled depends $learner. x Predictor data (independent variables), alternative interface data formula. y Response vector (dependent variable), alternative interface data formula. progress Logical; indicating whether print progress across cross validation folds.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"fit follows standard R modeling convention surfacing formula modeling interface well alternate matrix option. user use whichever interface supported specified $learner function.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"object class FittedGridSearch.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"","code":"if (require(e1071) && require(rpart) && require(rsample) && require(yardstick)) {   iris_new <- iris[sample(1:nrow(iris), nrow(iris)), ]   iris_new$Species <- factor(iris_new$Species == \"virginica\")   iris_train <- iris_new[1:100, ]   iris_validate <- iris_new[101:150, ]    ### Decision Tree example    iris_grid <- GridSearch$new(     learner = rpart::rpart,     learner_args = list(method = \"class\"),     tune_params = list(       minsplit = seq(10, 30, by = 5),       maxdepth = seq(20, 30, by = 2)     ),     evaluation_data = list(x = iris_validate[, 1:4], y = iris_validate$Species),     scorer = list(\"accuracy\" = yardstick::accuracy_vec),     optimize_score = \"max\",     prediction_args = list(\"accuracy\" = list(type = \"class\"))   )   iris_grid_fitted <- iris_grid$fit(     formula = Species ~ .,     data = iris_train   )    ### Example with multiple metric functions    iris_grid <- GridSearch$new(     learner = rpart::rpart,     learner_args = list(method = \"class\"),     tune_params = list(       minsplit = seq(10, 30, by = 5),       maxdepth = seq(20, 30, by = 2)     ),     evaluation_data = list(x = iris_validate, y = iris_validate$Species),     scorer = list(       \"accuracy\" = yardstick::accuracy_vec,       \"auc\" = yardstick::roc_auc_vec     ),     optimize_score = \"max\",     prediction_args = list(       \"accuracy\" = list(type = \"class\"),       \"auc\" = list(type = \"prob\")     ),     convert_predictions = list(       \"accuracy\" = NULL,       \"auc\" = function(i) i[, \"FALSE\"]     )   )   iris_grid_fitted <- iris_grid$fit(     formula = Species ~ .,     data = iris_train,   )    # Grab the best model   iris_grid_fitted$best_model    # Grab the best hyper-parameters   iris_grid_fitted$best_params    # Grab the best model performance metrics   iris_grid_fitted$best_metric    ### Matrix interface example - SVM    mtcars_train <- mtcars[1:25, ]   mtcars_eval <- mtcars[26:nrow(mtcars), ]    mtcars_grid <- GridSearch$new(     learner = e1071::svm,     tune_params = list(       \"degree\" = 2:4,       \"kernel\" = c(\"linear\", \"polynomial\")     ),     evaluation_data = list(x = mtcars_eval[, -1], y = mtcars_eval$mpg),     learner_args = list(scale = TRUE),     scorer = list(       \"rmse\" = yardstick::rmse_vec,       \"mae\" = yardstick::mae_vec     ),     optimize_score = \"min\"   )   mtcars_grid_fitted <- mtcars_grid$fit(     x = mtcars_train[, -1],     y = mtcars_train$mpg   )  }"},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"Create new GridSearch object.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"","code":"GridSearch$new(   learner = NULL,   tune_params = NULL,   evaluation_data = NULL,   scorer = NULL,   optimize_score = c(\"min\", \"max\"),   learner_args = NULL,   scorer_args = NULL,   prediction_args = NULL,   convert_predictions = NULL )"},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"learner Function estimates predictive model. essential function support either formula interface formula data arguments, alternate matrix interface x y arguments. tune_params named list specifying arguments $learner tune. evaluation_data two-element list containing following elements: x, validation data generate predicted values ; y, validation response values evaluate predictive performance. scorer named list metric functions evaluate model performance evaluation_data. provided metric function must truth estimate arguments, true outcome values predicted outcome values respectively, must return single numeric metric value. last metric function one used identify optimal model Grid Search. optimize_score One \"max\" \"min\"; Whether maximize minimize metric defined scorer find optimal Grid Search parameters. learner_args named list additional arguments pass learner. scorer_args named list additional arguments pass scorer. scorer_args must either length 1 length(scorer) case different arguments passed scoring function. prediction_args named list additional arguments pass predict. prediction_args must either length 1 length(scorer) case different arguments passed scoring function. convert_predictions list functions convert predicted values prior evaluated metric functions supplied scorer. list either length 1, case function applied predicted values, length(scorer) case function convert_predictions correspond function scorer.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"object class GridSearch.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"objects class cloneable method.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"","code":"GridSearch$clone(deep = FALSE)"},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"deep Whether make deep clone.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tune Predictive Model Hyper-parameters with Grid Search — GridSearch","text":"","code":"## ------------------------------------------------ ## Method `GridSearch$fit` ## ------------------------------------------------  if (require(e1071) && require(rpart) && require(rsample) && require(yardstick)) {   iris_new <- iris[sample(1:nrow(iris), nrow(iris)), ]   iris_new$Species <- factor(iris_new$Species == \"virginica\")   iris_train <- iris_new[1:100, ]   iris_validate <- iris_new[101:150, ]    ### Decision Tree example    iris_grid <- GridSearch$new(     learner = rpart::rpart,     learner_args = list(method = \"class\"),     tune_params = list(       minsplit = seq(10, 30, by = 5),       maxdepth = seq(20, 30, by = 2)     ),     evaluation_data = list(x = iris_validate[, 1:4], y = iris_validate$Species),     scorer = list(\"accuracy\" = yardstick::accuracy_vec),     optimize_score = \"max\",     prediction_args = list(\"accuracy\" = list(type = \"class\"))   )   iris_grid_fitted <- iris_grid$fit(     formula = Species ~ .,     data = iris_train   )    ### Example with multiple metric functions    iris_grid <- GridSearch$new(     learner = rpart::rpart,     learner_args = list(method = \"class\"),     tune_params = list(       minsplit = seq(10, 30, by = 5),       maxdepth = seq(20, 30, by = 2)     ),     evaluation_data = list(x = iris_validate, y = iris_validate$Species),     scorer = list(       \"accuracy\" = yardstick::accuracy_vec,       \"auc\" = yardstick::roc_auc_vec     ),     optimize_score = \"max\",     prediction_args = list(       \"accuracy\" = list(type = \"class\"),       \"auc\" = list(type = \"prob\")     ),     convert_predictions = list(       \"accuracy\" = NULL,       \"auc\" = function(i) i[, \"FALSE\"]     )   )   iris_grid_fitted <- iris_grid$fit(     formula = Species ~ .,     data = iris_train,   )    # Grab the best model   iris_grid_fitted$best_model    # Grab the best hyper-parameters   iris_grid_fitted$best_params    # Grab the best model performance metrics   iris_grid_fitted$best_metric    ### Matrix interface example - SVM    mtcars_train <- mtcars[1:25, ]   mtcars_eval <- mtcars[26:nrow(mtcars), ]    mtcars_grid <- GridSearch$new(     learner = e1071::svm,     tune_params = list(       \"degree\" = 2:4,       \"kernel\" = c(\"linear\", \"polynomial\")     ),     evaluation_data = list(x = mtcars_eval[, -1], y = mtcars_eval$mpg),     learner_args = list(scale = TRUE),     scorer = list(       \"rmse\" = yardstick::rmse_vec,       \"mae\" = yardstick::mae_vec     ),     optimize_score = \"min\"   )   mtcars_grid_fitted <- mtcars_grid$fit(     x = mtcars_train[, -1],     y = mtcars_train$mpg   )  }"},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"GridSearchCV allows user specify Grid Search schema tuning predictive model hyper-parameters Cross-Validation. GridSearchCV gives user complete flexibility predictive model performance metrics.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"learner Predictive modeling function. scorer List performance metric functions. splitter Function splits data cross validation folds. tune_params Data.frame full hyper-parameter grid created $tune_params","code":""},{"path":[]},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"GridSearchCV$fit() GridSearchCV$new() GridSearchCV$clone()","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"method-fit-","dir":"Reference","previous_headings":"","what":"Method fit()","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"fit tunes user-specified model hyper-parameters via Grid Search Cross-Validation.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"","code":"GridSearchCV$fit(   formula = NULL,   data = NULL,   x = NULL,   y = NULL,   progress = FALSE )"},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"formula object class formula: symbolic description model fitted. data optional data frame, object containing variables model. data provided, formula handled depends $learner. x Predictor data (independent variables), alternative interface data formula. y Response vector (dependent variable), alternative interface data formula. progress Logical; indicating whether print progress across hyper-parameter grid.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"fit follows standard R modeling convention surfacing formula modeling interface well alternate matrix option. user use whichever interface supported specified $learner function.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"object class FittedGridSearchCV.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"","code":"\\dontrun{ if (require(e1071) && require(rpart) && require(rsample) && require(yardstick)) {   iris_new <- iris[sample(1:nrow(iris), nrow(iris)), ]   iris_new$Species <- factor(iris_new$Species == \"virginica\")   iris_train <- iris_new[1:100, ]   iris_validate <- iris_new[101:150, ]    # Create a sampling function that returns CV folds   sampling_fn <- function(data) lapply(rsample::vfold_cv(data, v = 3)$splits, \\(y) y$in_id)    ### Decision Tree example    iris_grid_cv <- GridSearchCV$new(     learner = rpart::rpart,     learner_args = list(method = \"class\"),     tune_params = list(       minsplit = seq(10, 30, by = 5),       maxdepth = seq(20, 30, by = 2)     ),     splitter = sampling_fn,     scorer = list(\"accuracy\" = yardstick::accuracy_vec),     optimize_score = \"max\",     prediction_args = list(\"accuracy\" = list(type = \"class\"))   )   iris_grid_cv_fitted <- iris_grid_cv$fit(     formula = Species ~ .,     data = iris_train   )    ### Example with multiple metric functions    iris_grid_cv <- GridSearchCV$new(     learner = rpart::rpart,     learner_args = list(method = \"class\"),     tune_params = list(       minsplit = seq(10, 30, by = 5),       maxdepth = seq(20, 30, by = 2)     ),     splitter = sampling_fn,     scorer = list(       \"accuracy\" = yardstick::accuracy_vec,       \"auc\" = yardstick::roc_auc_vec     ),     optimize_score = \"max\",     prediction_args = list(       \"accuracy\" = list(type = \"class\"),       \"auc\" = list(type = \"prob\")     ),     convert_predictions = list(       \"accuracy\" = NULL,       \"auc\" = function(i) i[, \"FALSE\"]     )   )   iris_grid_cv_fitted <- iris_grid_cv$fit(     formula = Species ~ .,     data = iris_train,   )    # Grab the best model   iris_grid_cv_fitted$best_model    # Grab the best hyper-parameters   iris_grid_cv_fitted$best_params    # Grab the best model performance metrics   iris_grid_cv_fitted$best_metric    ### Matrix interface example - SVM    mtcars_train <- mtcars[1:25, ]   mtcars_eval <- mtcars[26:nrow(mtcars), ]    mtcars_grid_cv <- GridSearchCV$new(     learner = e1071::svm,     tune_params = list(       \"degree\" = 2:4,       \"kernel\" = c(\"linear\", \"polynomial\")     ),     splitter = sampling_fn,     learner_args = list(scale = TRUE),     scorer = list(       \"rmse\" = yardstick::rmse_vec,       \"mae\" = yardstick::mae_vec     ),     optimize_score = \"min\"   )   mtcars_grid_cv_fitted <- mtcars_grid_cv$fit(     x = mtcars_train[, -1],     y = mtcars_train$mpg   )  } }"},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"Create new GridSearchCV object.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"","code":"GridSearchCV$new(   learner = NULL,   tune_params = NULL,   splitter = NULL,   scorer = NULL,   optimize_score = c(\"min\", \"max\"),   learner_args = NULL,   splitter_args = NULL,   scorer_args = NULL,   prediction_args = NULL,   convert_predictions = NULL )"},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"learner Function estimates predictive model. essential function support either formula interface formula data arguments, alternate matrix interface x y arguments. tune_params named list specifying arguments $learner tune. splitter function computes cross validation folds input data set pre-computed list cross validation fold indices. splitter function, must data argument input data, must return list cross validation fold indices. splitter list integers, number cross validation folds length(splitter) element contains indices data observations included fold. scorer named list metric functions evaluate model performance evaluation_data. provided metric function must truth estimate arguments, true outcome values predicted outcome values respectively, must return single numeric metric value. last metric function one used identify optimal model Grid Search. optimize_score One \"max\" \"min\"; Whether maximize minimize metric defined scorer find optimal Grid Search parameters. learner_args named list additional arguments pass learner. splitter_args named list additional arguments pass splitter. scorer_args named list additional arguments pass scorer. scorer_args must either length 1 length(scorer) case different arguments passed scoring function. prediction_args named list additional arguments pass predict. prediction_args must either length 1 length(scorer) case different arguments passed scoring function. convert_predictions list functions convert predicted values prior evaluated metric functions supplied scorer. list either length 1, case function applied predicted values, length(scorer) case function convert_predictions correspond function scorer.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"object class GridSearch.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"objects class cloneable method.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"","code":"GridSearchCV$clone(deep = FALSE)"},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"deep Whether make deep clone.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/GridSearchCV.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tune Predictive Model Hyper-parameters with Grid Search and Cross-Validation — GridSearchCV","text":"","code":"## ------------------------------------------------ ## Method `GridSearchCV$fit` ## ------------------------------------------------  if (FALSE) { # \\dontrun{ if (require(e1071) && require(rpart) && require(rsample) && require(yardstick)) {   iris_new <- iris[sample(1:nrow(iris), nrow(iris)), ]   iris_new$Species <- factor(iris_new$Species == \"virginica\")   iris_train <- iris_new[1:100, ]   iris_validate <- iris_new[101:150, ]    # Create a sampling function that returns CV folds   sampling_fn <- function(data) lapply(rsample::vfold_cv(data, v = 3)$splits, \\(y) y$in_id)    ### Decision Tree example    iris_grid_cv <- GridSearchCV$new(     learner = rpart::rpart,     learner_args = list(method = \"class\"),     tune_params = list(       minsplit = seq(10, 30, by = 5),       maxdepth = seq(20, 30, by = 2)     ),     splitter = sampling_fn,     scorer = list(\"accuracy\" = yardstick::accuracy_vec),     optimize_score = \"max\",     prediction_args = list(\"accuracy\" = list(type = \"class\"))   )   iris_grid_cv_fitted <- iris_grid_cv$fit(     formula = Species ~ .,     data = iris_train   )    ### Example with multiple metric functions    iris_grid_cv <- GridSearchCV$new(     learner = rpart::rpart,     learner_args = list(method = \"class\"),     tune_params = list(       minsplit = seq(10, 30, by = 5),       maxdepth = seq(20, 30, by = 2)     ),     splitter = sampling_fn,     scorer = list(       \"accuracy\" = yardstick::accuracy_vec,       \"auc\" = yardstick::roc_auc_vec     ),     optimize_score = \"max\",     prediction_args = list(       \"accuracy\" = list(type = \"class\"),       \"auc\" = list(type = \"prob\")     ),     convert_predictions = list(       \"accuracy\" = NULL,       \"auc\" = function(i) i[, \"FALSE\"]     )   )   iris_grid_cv_fitted <- iris_grid_cv$fit(     formula = Species ~ .,     data = iris_train,   )    # Grab the best model   iris_grid_cv_fitted$best_model    # Grab the best hyper-parameters   iris_grid_cv_fitted$best_params    # Grab the best model performance metrics   iris_grid_cv_fitted$best_metric    ### Matrix interface example - SVM    mtcars_train <- mtcars[1:25, ]   mtcars_eval <- mtcars[26:nrow(mtcars), ]    mtcars_grid_cv <- GridSearchCV$new(     learner = e1071::svm,     tune_params = list(       \"degree\" = 2:4,       \"kernel\" = c(\"linear\", \"polynomial\")     ),     splitter = sampling_fn,     learner_args = list(scale = TRUE),     scorer = list(       \"rmse\" = yardstick::rmse_vec,       \"mae\" = yardstick::mae_vec     ),     optimize_score = \"min\"   )   mtcars_grid_cv_fitted <- mtcars_grid_cv$fit(     x = mtcars_train[, -1],     y = mtcars_train$mpg   )  } } # }"},{"path":"https://www.dmolitor.com/modelselection/reference/cv_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate cross-validation fold indices — cv_split","title":"Generate cross-validation fold indices — cv_split","text":"Splits row indices data frame matrix k folds cross-validation.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/cv_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate cross-validation fold indices — cv_split","text":"","code":"cv_split(data, v = 5, seed = NULL)"},{"path":"https://www.dmolitor.com/modelselection/reference/cv_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate cross-validation fold indices — cv_split","text":"data data frame matrix. v Integer. Number folds. Defaults 5. seed Optional integer. Random seed reproducibility.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/cv_split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate cross-validation fold indices — cv_split","text":"list length v, element vector row indices fold.","code":""},{"path":"https://www.dmolitor.com/modelselection/reference/cv_split.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate cross-validation fold indices — cv_split","text":"","code":"folds <- cv_split(mtcars, v = 5, seed = 123) str(folds) #> List of 5 #>  $ : int [1:7] 1 9 21 24 26 29 32 #>  $ : int [1:7] 8 18 19 20 22 30 31 #>  $ : int [1:6] 5 7 13 16 17 28 #>  $ : int [1:6] 3 4 12 15 23 25 #>  $ : int [1:6] 2 6 10 11 14 27"},{"path":"https://www.dmolitor.com/modelselection/reference/modeltuning-package.html","id":null,"dir":"Reference","previous_headings":"","what":"modeltuning: Model Selection and Tuning Utilities — modeltuning-package","title":"modeltuning: Model Selection and Tuning Utilities — modeltuning-package","text":"Provides common model selection tuning utilities intuitive extremely flexible manner.","code":""},{"path":[]},{"path":"https://www.dmolitor.com/modelselection/reference/modeltuning-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"modeltuning: Model Selection and Tuning Utilities — modeltuning-package","text":"Maintainer: Daniel Molitor molitdj97@gmail.com","code":""}]
